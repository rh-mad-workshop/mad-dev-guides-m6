= 3. Training a model - 15 minutes
:imagesdir: ../assets/images

In this section, we will explore how data scientists are training models. It will be a very simple example, but it will give you the basics on the workflow.

* If you still have your sandbox notebook opened, please first close it:

image::close_sandbox.png[]

We also need to shut down the Jupyter notebook environment and pod, as for the rest of the workshop we will use a Data Science Project.

* If you still have you OpenShift Data Science dashboard tab opened in your browser, head to it. You can then simply close the JupyterLab tab, and select **Stop notebook server** on the dashboard:

image::stop_notebook_server.png[]

* If you had closed the OpenShift Data Science dashboard, you can access it https://rhods-dashboard-redhat-ods-applications.%SUBDOMAIN%[here^] or you can reopen it from Jupyter by clicking on **File->Hub Control Panel**:

image::hub_panel.png[]

It will reopen a tab with the dashboard, from which you can stop the notebook environment as described before. We are now ready to work in a Data Science Project.

== 3.1. Data Science Project

First, we will need a data science project to organize all our work: model training, model serving, application deployment. As we said earlier, a data science project is in fact an OpenShift project, but you don't need to leave the RHODS environment to create it!

=== 3.1.1. Creating the DSP

* Head to **Data Science Projects** and select **Create data science project**:

image::create_dsp.png[]

* Type the following values in the popup window. It will be the Display name for OpenShift, and the Resource name is automatically sanitized and created for you.

* *Name*: `%USERID% data science project`
* *Resource name*: `%USERID%-data-science-project`
* *Description*: `This is my first try at data science!`

image::create_dsp_modal.png[]

* Now, if you are curious and have a look at your https://console-openshift-console.%SUBDOMAIN%/k8s/cluster/projects/%USERID%-data-science-project[OpenShift console^], you will see that the project has indeed been created (login may be needed if you never connected to the Console):

image::my_dsp_console.png[]

=== 3.1.2. Working with the DSP

In a Data Science Project you have different sections:

* Workbenches are development environments. They can be based on JupyterLab, but also on other types of IDEs, like VS Code or RStudio. You can create as many workbenches as you want, and they can run concurrently.
* Cluster storage are Persistent Volumes Claims (PVCs), the persistent storage spaces you can use to store your notebooks and data. You can create them directly from here, and mount them in your workbenches as you like. Note that a default cluster storage (PVC) is always automatically created with a new workbench to save your work.
* Data connections are configurations for remote data location. At the moment, only S3-compatible Object Storage is supported. We will use this feature later on to configure the storage for our models.
* Finally, Model Servers are used to serve models! But let's save that for later.

For now, let's create a new workbench to work with Tensorflow to train models!

* select **Create workbench**

image::create_workbench.png[]

* Give it a name, select the **Tensorflow** image, with a Deployment size of **Small**, and a Cluster storage space of 1GB, it will be enough:

image::create_workbench_1.png[]
image::create_workbench_2.png[]

* And of course, select **Create workbench**:

image::create_workbench_click.png[]

* The workbench is created, first in the **Starting state**:

image::workbench_starting.png[]

You can use this toggle to easily start/stop this environment later on.

* When it is ready, the state will change to **Running** and you can select **Open** to go to your environment:

image::workbench_running.png[]

* After authentication and allowing permissions, you are again in your now familiar JupyterLab environment:

image::workbench_jl.png[]

== 3.2. Model training

We are now ready to do some serious work!

* Again, go to the Git menu on the left:

image::git.png[]

* Then select `Clone a Repository`:

image::git_clone.png[]

* Enter the URL https://github.com/rh-aiservices-bu/mad_m6_workshop.git, then select `CLONE`:

image::clone_repo.png[]

* It takes a few seconds, after which you can double-click and navigate to the newly-created folder, **mad_m6_workshop**:

image::open_mad_workshop.png[]

* In the `mad_m6_workshop` folder, open the file `02_model_training_basics`.

* Follow the steps in the notebook, and run each cell as you go. There may be an Error message when running the cell where `pip install` are done, but you can safely ignore it.

image::run_cell.png[]